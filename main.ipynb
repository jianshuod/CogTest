{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"/YOUR/LOCAL/DIR\"\n",
    "runname = \"trials\"\n",
    "\n",
    "\n",
    "def model_name_normalize(model_name: str) -> str:\n",
    "    return model_name.replace(\"/\", \"-\").replace(\" \", \"-\").replace(\".\", \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT elicitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import query_llm_with_instructions_parallel\n",
    "import os\n",
    "import json\n",
    "\n",
    "directory = os.path.join(workdir, \"assets/instructions\")\n",
    "\n",
    "instruction_set = set()\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                for item in data.get(\"instructions\", []):\n",
    "                    instruction = item.get(\"instruction\", \"\").strip()\n",
    "                    if instruction:\n",
    "                        instruction_set.add(instruction)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"File {file_path} could not be parsed as JSON, skipped.\")\n",
    "\n",
    "instructions = list(instruction_set)\n",
    "\n",
    "models = [\"gpt-4o\"]\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "output_dir_base = os.path.join(workdir, \"assets/results\", runname, \"responses\")\n",
    "\n",
    "if not os.path.exists(output_dir_base):\n",
    "    os.makedirs(output_dir_base, exist_ok=True)\n",
    "\n",
    "for model in models:\n",
    "    output_dir = os.path.join(output_dir_base)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    results = query_llm_with_instructions_parallel(\n",
    "        model, instructions[:10], num_workers=32, output_dir_base=output_dir, **gen_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Habit Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import concurrent.futures\n",
    "from collections import Counter, defaultdict\n",
    "from src.tools import judge_habit_occurrence_by_showing_evidence_with_format_enforcement_system, habit_example_mapping\n",
    "\n",
    "models = [\n",
    "    \"gpt-4o\"\n",
    "]\n",
    "\n",
    "output_base_path = os.path.join(workdir, \"assets/results\", runname)\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "response_output_path = os.path.join(output_base_path, \"responses\")\n",
    "if not os.path.exists(response_output_path):\n",
    "    raise ValueError(f\"Response output path {response_output_path} does not exist\")\n",
    "annotation_output_path = os.path.join(output_base_path, \"annotations\")\n",
    "os.makedirs(annotation_output_path, exist_ok=True)\n",
    "habit_count_dir = os.path.join(output_base_path, \"habit_counts\")\n",
    "os.makedirs(habit_count_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "instructions_base = os.path.join(workdir, \"assets/instructions\")\n",
    "\n",
    "\n",
    "def clean_habit_name(habit_key: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]\", \"\", habit_key.replace(\" \", \"_\"))\n",
    "\n",
    "# Build mapping from instructions to habits\n",
    "instruction_to_habits = defaultdict(list)\n",
    "for habit_key in habit_example_mapping.keys():\n",
    "    clean_name = clean_habit_name(habit_key)\n",
    "    file_path = os.path.join(instructions_base, f\"{clean_name}.json\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: Missing habit file {file_path}\")\n",
    "        continue\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            for instruction_entry in data.get(\"instructions\", []):\n",
    "                instruction = instruction_entry[\"instruction\"].strip()\n",
    "                instruction_to_habits[instruction].append(habit_key)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "def process_habit_for_model(r, model, instruction_to_habits, processed_keys, fout, global_counter):\n",
    "    instr = r[\"instruction\"].strip()\n",
    "    thinking = r[\"thinking\"][model].strip()\n",
    "    related_habits = instruction_to_habits.get(instr, [])\n",
    "    if not related_habits:\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "    for habit in related_habits:\n",
    "        uniq_key = (instr, habit)\n",
    "        if uniq_key in processed_keys:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            llm_result = judge_habit_occurrence_by_showing_evidence_with_format_enforcement_system(thinking=thinking, habit=habit)\n",
    "            is_refl = bool(llm_result.get(\"is_reflected\", False))\n",
    "            judge_flag = 1 if is_refl else 0\n",
    "            if is_refl:\n",
    "                global_counter[habit] += 1\n",
    "\n",
    "            rec = {\n",
    "                \"instruction\": instr,\n",
    "                \"thinking\": r[\"thinking\"],\n",
    "                \"llm_judge\": llm_result,\n",
    "                \"judge\": judge_flag,\n",
    "                \"habit\": habit\n",
    "            }\n",
    "            results.append(rec)\n",
    "            processed_keys.add(uniq_key)\n",
    "        except Exception as e:\n",
    "            print(f\"Error judging habit {habit} for model {model}: {str(e)}\")\n",
    "            return None\n",
    "    return results\n",
    "\n",
    "def parallel_processing_for_model(model):\n",
    "    input_file_path = f\"{response_output_path}/{model_name_normalize(model)}.jsonl\"\n",
    "    os.makedirs(os.path.dirname(input_file_path), exist_ok=True)\n",
    "    annotated_output_file = os.path.join(annotation_output_path, f\"{model_name_normalize(model)}.jsonl\")\n",
    "    os.makedirs(os.path.dirname(annotated_output_file), exist_ok=True)\n",
    "\n",
    "    # Load the original data\n",
    "    results = []\n",
    "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                result = json.loads(line.strip())\n",
    "                if \"thinking\" in result and model in result[\"thinking\"]:\n",
    "                    thinking_str = result[\"thinking\"][model]\n",
    "                    if isinstance(thinking_str, str):\n",
    "                        result[\"thinking\"][model] = thinking_str.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "                results.append(result)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error in {model_name_normalize(model)}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Processed keys\n",
    "    processed_keys = set()\n",
    "    global_counter = Counter()\n",
    "\n",
    "    if os.path.exists(annotated_output_file):\n",
    "        with open(annotated_output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    record = json.loads(line.strip())\n",
    "                    instr = record.get(\"instruction\", \"\").strip()\n",
    "                    habit = record.get(\"habit\", None)\n",
    "                    judge = record.get(\"judge\", None)\n",
    "                    if habit is not None:\n",
    "                        processed_keys.add((instr, habit))\n",
    "                        if judge == 1:\n",
    "                            global_counter[habit] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Failed to load rec from {annotated_output_file}: {e}\")\n",
    "\n",
    "    fout = open(annotated_output_file, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "    # Use ThreadPoolExecutor to process tasks in parallel\n",
    "    num_total_to_process = 0\n",
    "    num_skipped = 0\n",
    "    num_processed_now = 0\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        futures = []\n",
    "        for r in results:\n",
    "            futures.append(executor.submit(process_habit_for_model, r, model, instruction_to_habits, processed_keys, fout, global_counter))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            task_results = future.result()\n",
    "            if task_results:\n",
    "                num_processed_now += len(task_results)\n",
    "                for rec in task_results:\n",
    "                    fout.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "                    fout.flush()\n",
    "\n",
    "    fout.close()\n",
    "\n",
    "    # Print the summary\n",
    "    print(f\"\\n[{model}]\")\n",
    "    print(f\"Total tasks related to habits: {num_total_to_process}\")\n",
    "    print(f\"Skipped (already processed): {num_skipped}\")\n",
    "    print(f\"Processed newly this run: {num_processed_now}\")\n",
    "    for habit, count in global_counter.items():\n",
    "        print(f\"{habit}: {count}\")\n",
    "\n",
    "    output_file = os.path.join(habit_count_dir, f\"{model_name_normalize(model)}.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dict(global_counter), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Main driver to process all models\n",
    "for model in models:\n",
    "    parallel_processing_for_model(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CogTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
